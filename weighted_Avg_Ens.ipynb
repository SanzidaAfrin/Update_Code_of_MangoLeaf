{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34b4148b-db5c-4d89-80af-ae737b95f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3,MobileNetV2\n",
    "from tensorflow.keras.models import Model,save_model,load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D, BatchNormalization,Dropout,Input,Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdb3d722-f5d9-4ac9-8d7a-08bcd8eb1e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =r\"E:\\1. Thesis\\Update_Code\\Dataset\"\n",
    "keyword= ['Anthracnose','Bacterial Canker','Cutting Weevil','Die Back','Gall Midge','Healthy','Powdery Mildew','Sooty Mould']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b87bf7f-d66b-455e-bfdd-c9f7bef127b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classes: ['Anthracnose' 'Bacterial Canker' 'Cutting Weevil' 'Die Back' 'Gall Midge'\n",
      " 'Healthy' 'Powdery Mildew' 'Sooty Mould']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "Anthracnose         500\n",
       "Bacterial Canker    500\n",
       "Cutting Weevil      500\n",
       "Die Back            500\n",
       "Gall Midge          500\n",
       "Healthy             500\n",
       "Powdery Mildew      500\n",
       "Sooty Mould         500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_folders=os.listdir(data_dir)\n",
    "image_paths=[]\n",
    "labels=[]\n",
    "\n",
    "for class_folder in class_folders:\n",
    "    for key in keyword:\n",
    "        if key in class_folder:\n",
    "                class_path=os.path.join(data_dir,class_folder)\n",
    "                image_files=os.listdir(class_path)\n",
    "                for image_file in image_files:\n",
    "                    image_path=os.path.join(class_path,image_file)\n",
    "                    image_paths.append(image_path)\n",
    "                    labels.append(class_folder)\n",
    "    \n",
    "df=pd.DataFrame({'image_path':image_paths,'label':labels})\n",
    "print(\"The classes:\",np.unique(df['label']))\n",
    "\n",
    "class_counts=df['label'].value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18df8932-9439-458e-95dd-04c931ad9a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train(60%) and the rest(40%)\n",
    "train_df, rest_df = train_test_split(df,test_size=0.4, random_state=42)\n",
    "\n",
    "#split valiidation(50%) and test(50%)\n",
    "val_df, test_df = train_test_split(rest_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b51ad300-a33e-4c89-bb20-c51e69bd7c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2400 validated image filenames belonging to 8 classes.\n",
      "Found 800 validated image filenames belonging to 8 classes.\n",
      "Found 800 validated image filenames belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "def load_images_for_cnn(train_df, \n",
    "                        val_df, \n",
    "                        test_df, \n",
    "                        batch_size=32, \n",
    "                        target_size=(224,224)):\n",
    "\n",
    "    train_datagen=ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    train_generator=train_datagen.flow_from_dataframe(\n",
    "        train_df,\n",
    "        x_col='image_path',\n",
    "        y_col='label',\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "    validation_generator = validation_datagen.flow_from_dataframe(\n",
    "        val_df,\n",
    "        x_col='image_path',\n",
    "        y_col='label',\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "        test_df,\n",
    "        x_col='image_path',\n",
    "        y_col='label',\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    return train_generator,validation_generator,test_generator\n",
    "\n",
    "train_generator,validation_generator,test_generator=load_images_for_cnn(train_df,\n",
    "                                                                        val_df, \n",
    "                                                                        test_df, \n",
    "                                                                        batch_size=32, \n",
    "                                                                        target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a65fd87-e6c9-4872-a8cb-cae1fb88a511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load Models\n",
    "model_path1 = r\"E:\\1. Thesis\\Update_Code\\SavedModel\\DenseNet1213F.hdf5\"\n",
    "m1 = load_model(model_path1)\n",
    "m1 = Model(inputs=m1.inputs, outputs=m1.outputs, name='DenseNet121') \n",
    "\n",
    "model_path2 = r\"E:\\1. Thesis\\Update_Code\\SavedModel\\ResNet152V2.hdf5\"\n",
    "m2 = load_model(model_path2)\n",
    "m2 = Model(inputs=m2.inputs, outputs=m2.outputs, name='ResNet152V2')\n",
    "\n",
    "model_path3 = r\"E:\\1. Thesis\\Update_Code\\SavedModel\\InceptionV3F.hdf5\"\n",
    "m3 = load_model(model_path3)\n",
    "m3 = Model(inputs=m3.inputs, outputs=m3.outputs, name='InceptionV3') \n",
    "\n",
    "\n",
    "models=[m1,m2,m3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3df7706-4003-4966-b00c-4e5b2bee8a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "\n",
    "models = [m1, m2, m3]\n",
    "model_input = Input(shape=(224,224,3), name=\"ensemble_input\")\n",
    "\n",
    "# Ensure model outputs are single tensors, not lists\n",
    "model_outputs = [model(model_input) for model in models]\n",
    "\n",
    "# If any output is wrapped in a list/tuple, extract the first tensor\n",
    "model_outputs = [output[0] if isinstance(output, (list, tuple)) else output for output in model_outputs]\n",
    "\n",
    "# Merge outputs\n",
    "ensemble_output = Average()(model_outputs)\n",
    "\n",
    "# Create ensemble model\n",
    "ensemble_model = Model(inputs=model_input, outputs=ensemble_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f05e93c4-238b-422b-abb4-e17c940250f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'keras.src.backend.common.keras_tensor.KerasTensor'>, <class 'keras.src.backend.common.keras_tensor.KerasTensor'>, <class 'keras.src.backend.common.keras_tensor.KerasTensor'>]\n",
      "[(None, 8), (None, 8), (None, 8)]\n"
     ]
    }
   ],
   "source": [
    "print([type(output) for output in model_outputs])\n",
    "print([output.shape for output in model_outputs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00e34336-6d62-4f3d-86e1-078aa0945aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "ensemble_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), \n",
    "                       loss='categorical_crossentropy', \n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a467b921-5223-46ea-9e1b-cef58bd997c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanzida\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanzida\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['input_layer']\n",
      "Received: inputs=Tensor(shape=(None, 224, 224, 3))\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Sanzida\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['input_layer_2']\n",
      "Received: inputs=Tensor(shape=(None, 224, 224, 3))\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Sanzida\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['input_layer_1']\n",
      "Received: inputs=Tensor(shape=(None, 224, 224, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1808s\u001b[0m 23s/step - accuracy: 0.9701 - loss: 0.2707 - val_accuracy: 0.9725 - val_loss: 0.2167\n",
      "Epoch 2/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1673s\u001b[0m 22s/step - accuracy: 0.9681 - loss: 0.2429 - val_accuracy: 0.9762 - val_loss: 0.1933\n",
      "Epoch 3/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1750s\u001b[0m 23s/step - accuracy: 0.9782 - loss: 0.2097 - val_accuracy: 0.9750 - val_loss: 0.1749\n",
      "Epoch 4/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1535s\u001b[0m 20s/step - accuracy: 0.9831 - loss: 0.1894 - val_accuracy: 0.9775 - val_loss: 0.1591\n",
      "Epoch 5/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1395s\u001b[0m 19s/step - accuracy: 0.9788 - loss: 0.1743 - val_accuracy: 0.9787 - val_loss: 0.1467\n",
      "Epoch 6/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1372s\u001b[0m 18s/step - accuracy: 0.9799 - loss: 0.1677 - val_accuracy: 0.9887 - val_loss: 0.1331\n",
      "Epoch 7/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1546s\u001b[0m 21s/step - accuracy: 0.9825 - loss: 0.1504 - val_accuracy: 0.9800 - val_loss: 0.1288\n",
      "Epoch 8/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1342s\u001b[0m 18s/step - accuracy: 0.9809 - loss: 0.1460 - val_accuracy: 0.9862 - val_loss: 0.1185\n",
      "Epoch 9/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1750s\u001b[0m 23s/step - accuracy: 0.9848 - loss: 0.1381 - val_accuracy: 0.9875 - val_loss: 0.1118\n",
      "Epoch 10/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1590s\u001b[0m 21s/step - accuracy: 0.9836 - loss: 0.1334 - val_accuracy: 0.9887 - val_loss: 0.1061\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "epochs = 10\n",
    "training_history = ensemble_model.fit(train_generator, epochs=epochs, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6080afdf-b0e9-4a15-b14b-70f35a34ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedAverageLayer(tf.keras.layers.Layer):  # Corrected Layer inheritance\n",
    "    def __init__(self, w1, w2, w3, **kwargs):  # Corrected constructor\n",
    "        super(WeightedAverageLayer, self).__init__(**kwargs)  # Corrected super call\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "        self.w3 = w3\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.w1 * inputs[0] + self.w2 * inputs[1] + self.w3 * inputs[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17ca7308-594c-4556-b77b-1a0ac3b09673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sanzida\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sanzida\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_output=WeightedAverageLayer(0.6,0.3,0.1)(model_outputs)\n",
    "ensemble_model = Model(inputs=model_input, outputs=ensemble_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56a03b6b-e6f0-4ca8-b437-1bf0625931b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "ensemble_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), \n",
    "                       loss='categorical_crossentropy', \n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4285c8b4-73e8-465d-9ec0-86d51403179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1693s\u001b[0m 20s/step - accuracy: 0.9877 - loss: 0.1308 - val_accuracy: 0.9875 - val_loss: 0.0987\n",
      "Epoch 2/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1370s\u001b[0m 18s/step - accuracy: 0.9906 - loss: 0.1165 - val_accuracy: 0.9887 - val_loss: 0.0913\n",
      "Epoch 3/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1353s\u001b[0m 18s/step - accuracy: 0.9889 - loss: 0.1191 - val_accuracy: 0.9900 - val_loss: 0.0855\n",
      "Epoch 4/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6054s\u001b[0m 82s/step - accuracy: 0.9867 - loss: 0.1096 - val_accuracy: 0.9912 - val_loss: 0.0803\n",
      "Epoch 5/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9191s\u001b[0m 124s/step - accuracy: 0.9911 - loss: 0.1038 - val_accuracy: 0.9900 - val_loss: 0.0775\n",
      "Epoch 6/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1383s\u001b[0m 18s/step - accuracy: 0.9911 - loss: 0.0961 - val_accuracy: 0.9925 - val_loss: 0.0738\n",
      "Epoch 7/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3998s\u001b[0m 54s/step - accuracy: 0.9904 - loss: 0.1007 - val_accuracy: 0.9937 - val_loss: 0.0693\n",
      "Epoch 8/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2310s\u001b[0m 31s/step - accuracy: 0.9934 - loss: 0.0847 - val_accuracy: 0.9937 - val_loss: 0.0661\n",
      "Epoch 9/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1355s\u001b[0m 18s/step - accuracy: 0.9888 - loss: 0.0896 - val_accuracy: 0.9937 - val_loss: 0.0630\n",
      "Epoch 10/10\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1371s\u001b[0m 18s/step - accuracy: 0.9911 - loss: 0.0941 - val_accuracy: 0.9950 - val_loss: 0.0615\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "epochs = 10\n",
    "training_history = ensemble_model.fit(train_generator, \n",
    "                                      epochs=epochs, \n",
    "                                      validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc63a0-8be7-42bd-82e1-e1ad9ce514fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
